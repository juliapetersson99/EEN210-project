{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./Train_data/Jacob_running.csv\n",
      "The average frequency is approximately 59.08 Hz\n",
      "Loaded 5820 samples\n",
      "Segmented into 96 windows\n",
      "Loading ./Train_data/Jacob_first_gym.csv\n",
      "The average frequency is approximately 59.65 Hz\n",
      "Loaded 7105 samples\n",
      "Segmented into 117 windows\n",
      "Loading ./Train_data/Julia_first_gym.csv\n",
      "The average frequency is approximately 61.00 Hz\n",
      "Loaded 5993 samples\n",
      "Segmented into 98 windows\n",
      "Loading ./Train_data/Julia_running.csv\n",
      "The average frequency is approximately 54.71 Hz\n",
      "Loaded 4971 samples\n",
      "Segmented into 81 windows\n",
      "Loading ./Train_data/julia_sitting_to_fall.csv\n",
      "The average frequency is approximately 60.64 Hz\n",
      "Loaded 4987 samples\n",
      "Segmented into 82 windows\n",
      "Loading ./Train_data/Marten_second.csv\n",
      "The average frequency is approximately 60.08 Hz\n",
      "Loaded 4800 samples\n",
      "Segmented into 79 windows\n",
      "Loading ./Train_data/Marten_first.csv\n",
      "The average frequency is approximately 60.96 Hz\n",
      "Loaded 2000 samples\n",
      "Segmented into 32 windows\n",
      "Loading ./Train_data/sara_first.csv\n",
      "The average frequency is approximately 60.48 Hz\n",
      "Loaded 4659 samples\n",
      "Segmented into 76 windows\n",
      "Loading ./Train_data/Marten_running.csv\n",
      "The average frequency is approximately 58.35 Hz\n",
      "Loaded 5537 samples\n",
      "Segmented into 91 windows\n",
      "Loading ./Train_data/Marten_first_gym.csv\n",
      "The average frequency is approximately 60.73 Hz\n",
      "Loaded 5625 samples\n",
      "Segmented into 92 windows\n",
      "Loading ./Train_data/Sara_first_gym.csv\n",
      "The average frequency is approximately 60.29 Hz\n",
      "Loaded 12038 samples\n",
      "Segmented into 199 windows\n",
      "Loading ./Train_data/Jacob_second_gym.csv\n",
      "The average frequency is approximately 53.60 Hz\n",
      "Loaded 3724 samples\n",
      "Segmented into 61 windows\n",
      "Loading ./Train_data/Julia_first.csv\n",
      "The average frequency is approximately 59.65 Hz\n",
      "Loaded 5800 samples\n",
      "Segmented into 95 windows\n",
      "Loading ./Train_data/Jacob_first.csv\n",
      "The average frequency is approximately 60.73 Hz\n",
      "Loaded 4700 samples\n",
      "Segmented into 77 windows\n",
      "After normalization:\n",
      "acceleration_x: min = 0.0000, max = 1.0000\n",
      "acceleration_y: min = 0.0000, max = 1.0000\n",
      "acceleration_z: min = 0.0000, max = 1.0000\n",
      "gyroscope_x: min = 0.0000, max = 1.0000\n",
      "gyroscope_y: min = 0.0000, max = 1.0000\n",
      "gyroscope_z: min = 0.0000, max = 1.0000\n",
      "Label to index mapping: {np.str_('falling'): 0, np.str_('lying'): 1, np.str_('recover'): 2, np.str_('running'): 3, np.str_('sitting'): 4, np.str_('standing'): 5, np.str_('walking'): 6}\n",
      "X shape: (1276, 120, 6)\n",
      "y shape: (1276,)\n",
      "Number of data points per class: {np.int64(0): np.int64(72), np.int64(1): np.int64(95), np.int64(2): np.int64(102), np.int64(3): np.int64(49), np.int64(4): np.int64(185), np.int64(5): np.int64(444), np.int64(6): np.int64(329)}\n"
     ]
    }
   ],
   "source": [
    "import process as pp\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import CNN_LSTM\n",
    "from CNN_LSTM import CNN_LSTM  # Add this line to import the class specifically\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "lr = 0.0001\n",
    "\n",
    "fs = 60\n",
    "window_duration_sec = 2\n",
    "overlap = 0.5\n",
    "\n",
    "\n",
    "X, y = pp.load_and_preprocess_data('./Train_data', window_duration_sec, fs, overlap)\n",
    "y_encoded, label_to_idx = pp.encode_labels(y)\n",
    "print(\"Label to index mapping:\", label_to_idx)\n",
    "print(\"X shape:\", X.shape)  \n",
    "print(\"y shape:\", y_encoded.shape)\n",
    "\n",
    "unique, counts = np.unique(y_encoded, return_counts=True)\n",
    "class_counts = dict(zip(unique, counts))\n",
    "print(\"Number of data points per class:\", class_counts)\n",
    "\n",
    "\n",
    "#n_samples, window_length, num_channels = X.shape\n",
    "#X_flat = X.reshape(n_samples, window_length * num_channels)\n",
    "#print(\"Flattened X shape:\", X_flat.shape)  \n",
    "#Smote, not sure if it works now when we have timne series data\n",
    "#smote = SMOTE(random_state=198)\n",
    "\n",
    "#X_res_flat, y_res = smote.fit_resample(X_flat, y)\n",
    "#print(\"New label distribution:\", Counter(y_res))\n",
    "#X_res = X_res_flat.reshape(-1, window_length, num_channels)\n",
    "#print(\"Resampled X shape:\", X_res.shape)\n",
    "\n",
    "# Split into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=19, stratify=y_encoded)\n",
    "\n",
    "window_length = fs * window_duration_sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobjustad/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'label_to_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, models\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[0;32m----> 5\u001b[0m num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[43mlabel_to_idx\u001b[49m)\n\u001b[1;32m      6\u001b[0m window_size \u001b[38;5;241m=\u001b[39m window_length  \u001b[38;5;66;03m# If each sample is (window_size, 6)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m num_channels \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]  \u001b[38;5;66;03m# Should be 6 in your case\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'label_to_idx' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "num_classes=len(label_to_idx)\n",
    "window_size = window_length  # If each sample is (window_size, 6)\n",
    "num_channels = X_train.shape[2]  # Should be 6 in your case\n",
    "n_slices = 4                     # For example, same as reference\n",
    "slice_length = window_size // n_slices  # Must divide evenly\n",
    "\n",
    "# Input layer: (window_size, 6)\n",
    "input_layer = layers.Input(shape=(window_size, num_channels))\n",
    "\n",
    "# Reshape to (None, n_slices, slice_length, num_channels)\n",
    "reshaped = layers.Reshape((n_slices, slice_length, num_channels))(input_layer)\n",
    "\n",
    "# TimeDistributed Conv1D\n",
    "td_conv = layers.TimeDistributed(\n",
    "    layers.Conv1D(filters=64, kernel_size=3, activation='relu')\n",
    ")(reshaped)\n",
    "\n",
    "# TimeDistributed MaxPooling\n",
    "td_pool = layers.TimeDistributed(\n",
    "    layers.MaxPooling1D(pool_size=2)\n",
    ")(td_conv)\n",
    "\n",
    "# TimeDistributed Flatten\n",
    "td_flat = layers.TimeDistributed(layers.Flatten())(td_pool)\n",
    "\n",
    "# LSTM\n",
    "#DATA\n",
    "# If y is integer-encoded, we can use 'sparse_categorical_crossentropy';\n",
    "# if y is one-hot, use 'categorical_crossentropy'.\n",
    "lstm_out = layers.LSTM(128, activation='tanh')(td_flat)\n",
    "\n",
    "# Output: e.g. classification\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(lstm_out)\n",
    "\n",
    "model = models.Model(inputs=input_layer, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=epochs, \n",
    "    batch_size=batch_size, \n",
    "    validation_data=(X_test, y_test)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 4) Evaluate on train and test data\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(f\"[TRAIN]   Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"[TEST]    Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 5) Detailed metrics (classification report, confusion matrix)\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "print(\"\\nClassification Report (Test):\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix (Test):\\n\", confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
